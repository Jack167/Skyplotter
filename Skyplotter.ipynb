{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import unicodecsv as csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from vader import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def twitter_stream(file_name, coordinates, tweets_limit):\n",
    "    '''\n",
    "       Parameters\n",
    "       ----------\n",
    "       file_name          : string, file's name to be saved as.\n",
    "       coordinates        : list, box corners' coordinates to catch tweets.\n",
    "       tweets_limit       : int, number of tweets to capture.\n",
    "\n",
    "       Returns\n",
    "       ----------\n",
    "       file with captured tweets\n",
    "    '''\n",
    "    file =  open(file_name+'.txt', 'a+', encoding='utf-8')\n",
    "    \n",
    "    ckey = \"***\"\n",
    "    csecret = \"***\"\n",
    "    atoken = \"***\"\n",
    "    asecret = \"***\"\n",
    "    \n",
    "    class listener(StreamListener):\n",
    "\n",
    "        def __init__(self, api=None):\n",
    "            super(listener, self).__init__()\n",
    "            self.num_tweets = 0\n",
    "\n",
    "        def on_data(self, data):\n",
    "            # Twitter returns data in JSON format - we need to decode it first\n",
    "            try:\n",
    "                decoded = json.loads(data)\n",
    "            except Exception as e:\n",
    "                print (e) #we don't want the listener to stop\n",
    "                return True\n",
    "\n",
    "            if decoded.get('geo') is not None:\n",
    "                location = decoded.get('geo').get('coordinates')\n",
    "            elif decoded.get('user').get('location') != None:\n",
    "                location = '[' + decoded.get('user').get('location') + ']'\n",
    "            else:\n",
    "                location = decoded.get('user').get('location')\n",
    "            text = decoded['text'].replace('\\n',' ')\n",
    "            user = '@' + decoded.get('user').get('screen_name')\n",
    "            created = decoded.get('created_at')\n",
    "\n",
    "            file.write('{0}|{1}|{2}|{3}\\n'.format(user,location,created,text))\n",
    "                \n",
    "            print('{0}|{1}|{2}|{3}|{4}\\n'.format(self.num_tweets,user,location,created,text))\n",
    "\n",
    "            self.num_tweets += 1\n",
    "            if self.num_tweets < tweets_limit:\n",
    "                return True\n",
    "            else:\n",
    "                file.close()\n",
    "                return False\n",
    "\n",
    "        def on_error(self, status):\n",
    "            print(status)\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        print('Starting')\n",
    "\n",
    "        auth = OAuthHandler(ckey, csecret)\n",
    "        auth.set_access_token(atoken, asecret)\n",
    "        twitterStream = Stream(auth, listener())\n",
    "        twitterStream.filter(locations=coordinates)\n",
    "\n",
    "    \n",
    "def get_coordinates(file_name, coordinates, vader_score = False, fill_random = True):\n",
    "    '''\n",
    "       Parameters\n",
    "       ----------\n",
    "       file_name          : string, file's name to be analized.\n",
    "       coordinates        : list, box corners' coordinates.\n",
    "       vader_score        : bool, default False, gets sentiment score of file's tweets and saves coordinates' list\n",
    "                            grouped by sentiment score (positive, neutral and negative) in three different files.\n",
    "                            If False, it will only save one file with all the coordinates.\n",
    "       fill_random        : bool, default True, fills empty coordinates with random numbers within coordinates range.\n",
    "\n",
    "       Returns\n",
    "       ----------\n",
    "       file with coordinates (three files if vader_score = True). \n",
    "    '''\n",
    "    lon_min, lat_min, lon_max, lat_max = coordinates\n",
    "    tweets = pd.read_table(file_name + '.txt', sep = \"|\", names = [\"user\",\"location\",\"date\",\"text\"])\n",
    "    \n",
    "    if fill_random:\n",
    "        tweets['lat'] = tweets.location.apply(lambda x: x.split(',')[0].replace('[','') if ',' in x else np.nan)\n",
    "        tweets['lon'] = tweets.location.apply(lambda x: x.split(',')[1].replace(']','') if ',' in x else np.nan)\n",
    "\n",
    "        tweets['lat'] = tweets.lat.convert_objects(convert_numeric=True)\n",
    "        tweets['lon'] = tweets.lon.convert_objects(convert_numeric=True)\n",
    "        tweets.loc[tweets['lat'].isnull(), 'lat'] = np.random.uniform(lat_min, lat_max, tweets.loc[tweets['lat'].isnull(), 'lat'].size)\n",
    "        tweets.loc[tweets['lon'].isnull(), 'lon'] = np.random.uniform(lon_min, lon_max, tweets.loc[tweets['lon'].isnull(), 'lon'].size)\n",
    "    else:\n",
    "        tweets['lat'] = tweets.location.apply(lambda x: x.split(',')[0].replace('[','') if ',' in x else None)\n",
    "        tweets['lon'] = tweets.location.apply(lambda x: x.split(',')[1].replace(']','') if ',' in x else None)\n",
    "\n",
    "        tweets['lat'] = tweets.lat.convert_objects(convert_numeric=True)\n",
    "        tweets['lon'] = tweets.lon.convert_objects(convert_numeric=True)\n",
    "        \n",
    "        tweets = tweets.dropna()\n",
    "        \n",
    "    if vader_score:\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        tweets['score'] = tweets.text.apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "        def WriteCSV(csv_file, data_list):\n",
    "            with open(csv_file, 'wb') as csvfile:\n",
    "                writer = csv.writer(csvfile, dialect='excel', quoting=csv.QUOTE_NONNUMERIC)\n",
    "                for data in data_list:\n",
    "                    writer.writerow(data) \n",
    "            return\n",
    "\n",
    "        data_list_pos = zip(tweets.loc[tweets['score'] > 0.5, 'lat'], tweets.loc[tweets['score'] > 0.5, 'lon'])\n",
    "        data_list_neg = zip(tweets.loc[tweets['score'] < -0.5, 'lat'], tweets.loc[tweets['score'] <- 0.5, 'lon'])\n",
    "        data_list_neu = zip(tweets.loc[(tweets['score'] > -0.5) & (tweets['score'] < 0.5), 'lat'],\\\n",
    "                            (tweets.loc[(tweets['score'] > -0.5) & (tweets['score'] < 0.5), 'lon']))\n",
    "\n",
    "        WriteCSV(file_name + '_pos_points.csv', data_list_pos)\n",
    "        WriteCSV(file_name + '_neg_points.csv', data_list_neg)\n",
    "        WriteCSV(file_name + '_neu_points.csv', data_list_neu)\n",
    "    else:\n",
    "        data_list = zip(tweets['lat'],tweets['lon'])\n",
    "        csv_file = file_name + '_points.csv'\n",
    "\n",
    "        with open(csv_file, 'wb') as csvfile:\n",
    "            writer = csv.writer(csvfile, dialect='excel', quoting=csv.QUOTE_NONNUMERIC)\n",
    "            for data in data_list:\n",
    "                writer.writerow(data)\n",
    "        \n",
    "        \n",
    "def download_map(file_name, coordinates, quality = 15):\n",
    "    '''\n",
    "       Parameters\n",
    "       ----------\n",
    "       file_name          : string, file's name to be saved as.\n",
    "       coordinates        : list, box corners' coordinates.\n",
    "       quality            : int, default 15, map quality level.\n",
    "\n",
    "       Returns\n",
    "       ----------\n",
    "       image file of the map.\n",
    "       \n",
    "       Note: Requires to install osmviz library to work: pip install osmviz\n",
    "    '''\n",
    "    from osmviz.manager import PILImageManager, OSMManager\n",
    "    import PIL.Image as Image\n",
    "    \n",
    "    lon_min, lat_min, lon_max, lat_max = coordinates\n",
    "\n",
    "    imgr = PILImageManager('RGB')\n",
    "    osm = OSMManager(image_manager=imgr)\n",
    "    image, bnds = osm.createOSMImage((lat_min, lat_max, lon_min, lon_max), quality)\n",
    "    wh_ratio = float(image.size[0]) / image.size[1]\n",
    "    image2 = image.resize((int(800*wh_ratio), 800), Image.ANTIALIAS)\n",
    "    del image\n",
    "    image2.save(file_name + '_map.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coordinates = [-103.466492,20.522538,-103.213806,20.743593]\n",
    "\n",
    "file_name = 'tweets_try7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "twitter_stream(file_name, coordinates, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_coordinates(file_name, coordinates, vader_score = False, fill_random = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "download_map(file_name, coordinates, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Navy Blue\n",
    "%run heatmap.py -I file_name_map.bmp -o tweets_try_vader1.png -m 1996080ff -M 1996080ff\\\n",
    "    -e 20.522538,-103.466492,20.743593,-103.213806 tweets_try7_neu_points.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Green\n",
    "%run heatmap.py -I tweets_try_vader1.png -o tweets_try_vader1.png -m 359ffffff -M 359ffffff\\\n",
    "    -e 20.522538,-103.466492,20.743593,-103.213806 tweets_try7_neu_points.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Yellow\n",
    "%run heatmap.py -I tweets_try_vader1.png -o tweets_try_vader1.png -m 130ffffff -M 130ffffff\\\n",
    "    -e 20.522538,-103.466492,20.743593,-103.213806 tweets_try7_neu_points.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Red\n",
    "%run heatmap.py -I tweets_try_vader1.png -o tweets_try_vader1.png -m 100ffff00 -M 100ffff00\\\n",
    "    -e 20.522538,-103.466492,20.743593,-103.213806 -r 30 tweets_try7_neu_points.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
